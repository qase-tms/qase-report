---
phase: 12-stability-scoring
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/types/stability.ts
  - src/store/AnalyticsStore.ts
autonomous: true

must_haves:
  truths:
    - "System calculates stability grade (A+ to F) for tests with 10+ runs"
    - "Grade calculation uses pass rate (50%), flakiness (30%), duration variance (20%)"
    - "Tests with insufficient data (<10 runs) return grade 'N/A'"
    - "User can see underlying metrics: passRate, flakinessPercent, durationCV"
  artifacts:
    - path: "src/types/stability.ts"
      provides: "StabilityGrade type, StabilityResult interface, MIN_RUNS_STABILITY constant"
      exports: ["StabilityGrade", "StabilityResult", "MIN_RUNS_STABILITY", "GRADE_THRESHOLDS"]
    - path: "src/store/AnalyticsStore.ts"
      provides: "getStabilityScore method, testStabilityMap computed property"
      contains: "getStabilityScore"
  key_links:
    - from: "src/store/AnalyticsStore.ts"
      to: "src/types/stability.ts"
      via: "import StabilityGrade, StabilityResult"
      pattern: "import.*from.*stability"
    - from: "src/store/AnalyticsStore.ts"
      to: "src/store/HistoryStore.ts"
      via: "getTestHistory for duration data"
      pattern: "this\\.root\\.historyStore\\.getTestHistory"
---

<objective>
Implement stability scoring algorithm that calculates A+ to F grades based on weighted metrics.

Purpose: Enable test health assessment through objective, multi-factor grading (STAB-01).
Output: Types and AnalyticsStore method for stability grade calculation.
</objective>

<execution_context>
@/Users/gda/.claude/get-shit-done/workflows/execute-plan.md
@/Users/gda/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/store/AnalyticsStore.ts
@src/types/flakiness.ts
@src/types/alerts.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create stability types and constants</name>
  <files>src/types/stability.ts</files>
  <action>
Create stability type definitions following existing type patterns (flakiness.ts, alerts.ts).

Define:
1. `MIN_RUNS_STABILITY = 10` - minimum runs for accurate scoring (higher than flakiness MIN_RUNS=5 because stability considers more factors)

2. `StabilityGrade` type - literal union: 'A+' | 'A' | 'B' | 'C' | 'D' | 'F' | 'N/A'
   - N/A = insufficient data (less than MIN_RUNS_STABILITY)

3. `GRADE_THRESHOLDS` - exported const object mapping scores to grades:
   - 95-100: 'A+'
   - 90-94: 'A'
   - 80-89: 'B'
   - 70-79: 'C'
   - 60-69: 'D'
   - 0-59: 'F'

4. `StabilityResult` interface:
   - grade: StabilityGrade
   - score: number (0-100 composite score)
   - passRate: number (0-100 percentage)
   - flakinessPercent: number (0-100 from getFlakinessScore)
   - durationCV: number (coefficient of variation: stdDev/mean, as percentage)
   - totalRuns: number
   - minRunsRequired: number (for UI display when insufficient)

Add JSDoc comments explaining:
- The weighted formula: score = passRate*0.5 + (100-flakinessPercent)*0.3 + (100-cappedCV)*0.2
- Duration CV (coefficient of variation) measures consistency - lower is better
- CV is capped at 100% for scoring (extreme variance doesn't infinitely penalize)

Export all types and constants for use in AnalyticsStore.
  </action>
  <verify>
`grep -q "StabilityGrade" src/types/stability.ts && grep -q "MIN_RUNS_STABILITY" src/types/stability.ts && echo "Types created"`
  </verify>
  <done>
stability.ts exists with StabilityGrade type, StabilityResult interface, MIN_RUNS_STABILITY=10, and GRADE_THRESHOLDS constant.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement getStabilityScore in AnalyticsStore</name>
  <files>src/store/AnalyticsStore.ts</files>
  <action>
Add stability scoring to AnalyticsStore.

1. Import from stability.ts:
   `import { type StabilityGrade, type StabilityResult, MIN_RUNS_STABILITY, GRADE_THRESHOLDS } from '../types/stability'`

2. Add helper method `calculateDurationCV(durations: number[]): number`:
   - Calculate mean and stdDev using existing calculateStats method
   - Return (stdDev / mean) * 100 as percentage
   - Handle edge case: if mean is 0, return 0 (no variance)
   - Cap result at 100 (extreme variance shouldn't infinitely penalize)

3. Add helper function `scoreToGrade(score: number): StabilityGrade`:
   - Use GRADE_THRESHOLDS to map score to grade
   - Iterate thresholds from highest to lowest
   - Return matching grade

4. Add method `getStabilityScore(signature: string): StabilityResult`:
   - Get test history from HistoryStore: `this.root.historyStore.getTestHistory(signature)`
   - If runs.length < MIN_RUNS_STABILITY, return early with:
     ```
     { grade: 'N/A', score: 0, passRate: 0, flakinessPercent: 0, durationCV: 0, totalRuns: runs.length, minRunsRequired: MIN_RUNS_STABILITY }
     ```

   - Calculate passRate: (passedCount / totalRuns) * 100
     - Count passed status runs

   - Get flakinessPercent from existing getFlakinessScore(signature).flakinessPercent

   - Calculate durationCV using calculateDurationCV on run durations

   - Calculate composite score:
     `score = passRate * 0.5 + (100 - flakinessPercent) * 0.3 + (100 - durationCV) * 0.2`
     - Clamp score to 0-100 range

   - Determine grade using scoreToGrade(score)

   - Return complete StabilityResult

5. Add computed property `testStabilityMap`: Map<string, StabilityResult>
   - Iterate all tests from history
   - Call getStabilityScore for each signature
   - Filter out N/A grades (insufficient data)
   - Cache as MobX computed for reactivity

6. Add computed property `gradeDistribution`: Record<StabilityGrade, number>
   - Count tests per grade from testStabilityMap
   - Return object like { 'A+': 5, 'A': 10, 'B': 15, ... }
   - Useful for dashboard widget

Add JSDoc comments explaining the scoring formula and what each metric measures.
  </action>
  <verify>
`grep -q "getStabilityScore" src/store/AnalyticsStore.ts && grep -q "gradeDistribution" src/store/AnalyticsStore.ts && npm run build 2>&1 | grep -q "error" && echo "Build errors" || echo "Build OK"`
  </verify>
  <done>
AnalyticsStore has getStabilityScore(signature) returning StabilityResult, testStabilityMap computed, gradeDistribution computed. Build passes without errors.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add stability score integration tests</name>
  <files>src/store/AnalyticsStore.ts</files>
  <action>
Validate scoring algorithm with manual edge case checks in dev console:

1. Test MIN_RUNS boundary:
   - Test with 9 runs should return grade: 'N/A'
   - Test with 10 runs should return actual grade

2. Test grade thresholds:
   - Perfect test (100% pass, 0% flaky, 0% CV) should get A+
   - score = 100*0.5 + 100*0.3 + 100*0.2 = 100 -> A+

3. Test CV calculation:
   - Consistent durations (e.g., all 100ms) should have CV=0
   - Variable durations should have CV > 0

4. Verify gradeDistribution:
   - Should reflect actual test grades
   - Should exclude N/A tests

Add console.log statements in getStabilityScore during development, then remove before commit.

Run `npm run build` to verify no TypeScript errors.
Run `npm run dev` and check browser console for any runtime errors when loading history data.
  </action>
  <verify>
`npm run build 2>&1 | tail -5`
  </verify>
  <done>
Build succeeds. Algorithm handles edge cases: MIN_RUNS boundary returns N/A, perfect scores get A+, CV calculates correctly for consistent/variable durations.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. `npm run build` - TypeScript compilation succeeds
2. `grep -c "getStabilityScore" src/store/AnalyticsStore.ts` - method exists
3. `grep -c "gradeDistribution" src/store/AnalyticsStore.ts` - computed exists
4. src/types/stability.ts exports: StabilityGrade, StabilityResult, MIN_RUNS_STABILITY, GRADE_THRESHOLDS
</verification>

<success_criteria>
- stability.ts exists with types and constants
- AnalyticsStore.getStabilityScore(signature) returns StabilityResult
- Grade calculation uses weighted formula: passRate*0.5 + (100-flakiness)*0.3 + (100-CV)*0.2
- Tests with <10 runs return grade 'N/A'
- gradeDistribution computed provides grade counts
- Build passes without TypeScript errors
</success_criteria>

<output>
After completion, create `.planning/phases/12-stability-scoring/12-01-SUMMARY.md`
</output>
